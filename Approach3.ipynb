{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Approach3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5rYOiOhrnf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "6c32c76f-d077-4f3f-fe6e-b29aa3c63824"
      },
      "source": [
        "# !pip install tensorflow==2.0.0\n",
        "# !pip install tensorflow==1.15.0\n",
        "# !pip install keras==2.3.1\n",
        "# !pip install tensorflow-gpu\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers import Dense, LSTM, concatenate, Input, CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model, to_categorical\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import metrics\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzdQ2n9ors2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_matrix = pd.read_csv(\"descriptors.csv\")\n",
        "y_smiles_text = feature_matrix[\"molecule_smile\"]\n",
        "max_len = y_smiles_text.apply(len).max() #97\n",
        "feature_matrix = feature_matrix.drop(\"molecule_smile\", axis=1)\n",
        "n_features = feature_matrix.shape[1]\n",
        "X = y_smiles_text.apply(lambda x: '%' + x + '^')\n",
        "X_padded = X.apply(lambda x: x + '~'*(max_len-len(x)+2)) #99\n",
        "Y_padded = y_smiles_text.apply(lambda x: x + '^' + '~'*(max_len-len(x)+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZajBJwFQs3bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.Series(list(X_padded.sum()))\n",
        "Y = pd.Series(list(Y_padded.sum()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldgZ9ZFIr1ar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8d092e-a5a1-4ec9-9b05-7616111cf8e5"
      },
      "source": [
        "repeated_feature_matrix = []\n",
        "for idx, row in feature_matrix.iterrows():\n",
        "  for j in range(99):\n",
        "    repeated_feature_matrix.append(row)\n",
        "repeated_feature_matrix = np.array(repeated_feature_matrix)\n",
        "print(repeated_feature_matrix.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(333927, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5rCF1H9sKhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "71e382ce-26d1-46cf-e314-4221485f2a2b"
      },
      "source": [
        "data = pd.concat([X_padded, Y_padded, pd.DataFrame(feature_matrix)], axis=1)\n",
        "data.columns = ['X', 'Y']+list(data.columns[2:])\n",
        "data_train, data_test = train_test_split(data, test_size=0.2)\n",
        "data_train, data_val = train_test_split(data_train, test_size=0.2)\n",
        "X_train = data_train['X']\n",
        "Y_train = data_train['Y']\n",
        "F_train = data_train.drop(['X', 'Y'], axis=1)\n",
        "X_val = data_val['X']\n",
        "Y_val = data_val['Y']\n",
        "F_val = data_val.drop(['X', 'Y'], axis=1)\n",
        "X_test = data_test['X']\n",
        "Y_test = data_test['Y']\n",
        "F_test = data_test.drop(['X', 'Y'], axis=1)\n",
        "print(X_train.shape, Y_train.shape, F_train.shape)\n",
        "print(X_val.shape, Y_val.shape, F_val.shape)\n",
        "print(X_test.shape, Y_test.shape, F_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2158,) (2158,) (2158, 90)\n",
            "(540,) (540,) (540, 90)\n",
            "(675,) (675,) (675, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2GCDNItFjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e462101c-3bea-4aca-9cb6-bb144e4bbf55"
      },
      "source": [
        "X_train_char = pd.Series(list(X_train.sum()))\n",
        "Y_train_char = pd.Series(list(Y_train.sum()))\n",
        "repeated_feature_matrix_train = []\n",
        "for idx, row in F_train.iterrows():\n",
        "  for j in range(99):\n",
        "    repeated_feature_matrix_train.append(row)\n",
        "repeated_feature_matrix_train = np.array(repeated_feature_matrix_train)\n",
        "print(repeated_feature_matrix_train.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213642, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vflEDU3YtZCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b85d282-4956-4e5d-b583-8a65a4bcff64"
      },
      "source": [
        "X_val_char = pd.Series(list(X_val.sum()))\n",
        "Y_val_char = pd.Series(list(Y_val.sum()))\n",
        "repeated_feature_matrix_val = []\n",
        "for idx, row in F_val.iterrows():\n",
        "  for j in range(99):\n",
        "    repeated_feature_matrix_val.append(row)\n",
        "repeated_feature_matrix_val = np.array(repeated_feature_matrix_val)\n",
        "print(repeated_feature_matrix_val.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(53460, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvkNO6zAtpof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c0743b5-f2a0-4dd7-f0fb-e65aa8a93984"
      },
      "source": [
        "X_test_char = pd.Series(list(X_test.sum()))\n",
        "Y_test_char = pd.Series(list(Y_test.sum()))\n",
        "repeated_feature_matrix_test = []\n",
        "for idx, row in F_test.iterrows():\n",
        "  for j in range(99):\n",
        "    repeated_feature_matrix_test.append(row)\n",
        "repeated_feature_matrix_test = np.array(repeated_feature_matrix_test)\n",
        "print(repeated_feature_matrix_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66825, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3WWsaywsOfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50f5eee0-5e36-436b-aed1-f6a2d93fd377"
      },
      "source": [
        "vocab = list(set(list(list(X_train) + list(Y_train) + list(X_val))))\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELIogTHbsn1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQnJJUE3sZMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_idx = []\n",
        "for row in X_train_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  X_train_idx.append(row_idx)\n",
        "Y_train_idx = []\n",
        "for row in Y_train_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  Y_train_idx.append(row_idx)\n",
        "X_val_idx = []\n",
        "for row in X_val_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  X_val_idx.append(row_idx)\n",
        "Y_val_idx = []\n",
        "for row in Y_val_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  Y_val_idx.append(row_idx)\n",
        "X_test_idx = []\n",
        "for row in X_test_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  X_test_idx.append(row_idx)\n",
        "Y_test_idx = []\n",
        "for row in Y_test_char:\n",
        "  row_idx = vocab.index(row)\n",
        "  Y_test_idx.append(row_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzuS9r_5uU0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fe108627-8155-49ad-e057-cc479d185936"
      },
      "source": [
        "X_train_onehot = to_categorical(X_train_idx)\n",
        "X_val_onehot = to_categorical(X_val_idx)\n",
        "X_test_onehot = to_categorical(X_test_idx)\n",
        "\n",
        "Y_train_onehot = to_categorical(Y_train_idx)\n",
        "Y_val_onehot = to_categorical(Y_val_idx)\n",
        "Y_test_onehot = to_categorical(Y_test_idx)\n",
        "print(X_train_onehot.shape, Y_train_onehot.shape)\n",
        "print(X_val_onehot.shape, Y_val_onehot.shape)\n",
        "print(X_test_onehot.shape, Y_test_onehot.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213642, 38) (213642, 38)\n",
            "(53460, 38) (53460, 38)\n",
            "(66825, 38) (66825, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8yUxJHPugbc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3dcc9b06-3450-45f1-9a11-b96840273a53"
      },
      "source": [
        "X_F_train = np.concatenate([X_train_onehot, repeated_feature_matrix_train], axis=1)\n",
        "X_F_val = np.concatenate([X_val_onehot, repeated_feature_matrix_val], axis=1)\n",
        "X_F_test = np.concatenate([X_test_onehot, repeated_feature_matrix_test], axis=1)\n",
        "print(X_F_train.shape, Y_train_onehot.shape)\n",
        "print(X_F_val.shape, Y_val_onehot.shape)\n",
        "print(X_F_test.shape, Y_test_onehot.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213642, 128) (213642, 38)\n",
            "(53460, 128) (53460, 38)\n",
            "(66825, 128) (66825, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJZbTvSbu4YA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b50119ce-ffa2-4037-b345-5ebbab7cd4ec"
      },
      "source": [
        "encoder_inputs_train = X_F_train[:,np.newaxis,:]\n",
        "decoder_inputs_train = X_train_onehot[:,np.newaxis,:]\n",
        "decoder_outputs_train = Y_train_onehot[:,np.newaxis,:]\n",
        "encoder_inputs_val = X_F_val[:,np.newaxis,:]\n",
        "decoder_inputs_val = X_val_onehot[:,np.newaxis,:]\n",
        "decoder_outputs_val = Y_val_onehot[:,np.newaxis,:]\n",
        "encoder_inputs_test = X_F_test[:,np.newaxis,:]\n",
        "decoder_inputs_test = X_test_onehot[:,np.newaxis,:]\n",
        "decoder_outputs_test = Y_test_onehot[:,np.newaxis,:]\n",
        "print(encoder_inputs_train.shape, decoder_inputs_train.shape, decoder_outputs_train.shape)\n",
        "print(encoder_inputs_val.shape, decoder_inputs_val.shape, decoder_outputs_val.shape)\n",
        "print(encoder_inputs_test.shape, decoder_inputs_test.shape, decoder_outputs_test.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213642, 1, 128) (213642, 1, 38) (213642, 1, 38)\n",
            "(53460, 1, 128) (53460, 1, 38) (53460, 1, 38)\n",
            "(66825, 1, 128) (66825, 1, 38) (66825, 1, 38)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1L5bEPtydls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 64\n",
        "num_decoder_tokens = 38\n",
        "max_decoder_seq_length = 99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQgMy7Fju9HQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a559dd86-a77f-48a9-85a4-9bc773b02ea4"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, 128))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, 38))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(38, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, None, 128)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, None, 38)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 64), (None,  49408       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  [(None, None, 64), ( 26368       input_10[0][0]                   \n",
            "                                                                 lstm_9[0][1]                     \n",
            "                                                                 lstm_9[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 38)     2470        lstm_10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 78,246\n",
            "Trainable params: 78,246\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbzobU20vMSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c71dc32-c0be-4292-917e-519ad3bbc022"
      },
      "source": [
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[metrics.categorical_accuracy])\n",
        "checkpoint = ModelCheckpoint(\"model\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=5)\n",
        "history = model.fit([encoder_inputs_train, decoder_inputs_train], decoder_outputs_train,\n",
        "          batch_size=512,\n",
        "          epochs=100,\n",
        "          validation_data=([encoder_inputs_val, decoder_inputs_val], decoder_outputs_val),\n",
        "          callbacks=[checkpoint])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 213642 samples, validate on 53460 samples\n",
            "Epoch 1/100\n",
            "213642/213642 [==============================] - 8s 40us/step - loss: 0.6999 - categorical_accuracy: 0.7398 - val_loss: 0.7136 - val_categorical_accuracy: 0.7376\n",
            "Epoch 2/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6969 - categorical_accuracy: 0.7413 - val_loss: 0.7134 - val_categorical_accuracy: 0.7383\n",
            "Epoch 3/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6951 - categorical_accuracy: 0.7404 - val_loss: 0.7122 - val_categorical_accuracy: 0.7378\n",
            "Epoch 4/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6939 - categorical_accuracy: 0.7408 - val_loss: 0.7105 - val_categorical_accuracy: 0.7387\n",
            "Epoch 5/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6919 - categorical_accuracy: 0.7412 - val_loss: 0.7104 - val_categorical_accuracy: 0.7383\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy improved from -inf to 0.73827, saving model to model\n",
            "Epoch 6/100\n",
            "213642/213642 [==============================] - 7s 31us/step - loss: 0.6909 - categorical_accuracy: 0.7411 - val_loss: 0.7096 - val_categorical_accuracy: 0.7386\n",
            "Epoch 7/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6895 - categorical_accuracy: 0.7417 - val_loss: 0.7096 - val_categorical_accuracy: 0.7379\n",
            "Epoch 8/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6885 - categorical_accuracy: 0.7415 - val_loss: 0.7086 - val_categorical_accuracy: 0.7383\n",
            "Epoch 9/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6873 - categorical_accuracy: 0.7416 - val_loss: 0.7086 - val_categorical_accuracy: 0.7368\n",
            "Epoch 10/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6858 - categorical_accuracy: 0.7422 - val_loss: 0.7070 - val_categorical_accuracy: 0.7379\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy did not improve from 0.73827\n",
            "Epoch 11/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6848 - categorical_accuracy: 0.7422 - val_loss: 0.7064 - val_categorical_accuracy: 0.7380\n",
            "Epoch 12/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6838 - categorical_accuracy: 0.7425 - val_loss: 0.7061 - val_categorical_accuracy: 0.7393\n",
            "Epoch 13/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6825 - categorical_accuracy: 0.7425 - val_loss: 0.7068 - val_categorical_accuracy: 0.7377\n",
            "Epoch 14/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6816 - categorical_accuracy: 0.7425 - val_loss: 0.7068 - val_categorical_accuracy: 0.7382\n",
            "Epoch 15/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6804 - categorical_accuracy: 0.7427 - val_loss: 0.7055 - val_categorical_accuracy: 0.7383\n",
            "\n",
            "Epoch 00015: val_categorical_accuracy improved from 0.73827 to 0.73835, saving model to model\n",
            "Epoch 16/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6792 - categorical_accuracy: 0.7431 - val_loss: 0.7050 - val_categorical_accuracy: 0.7386\n",
            "Epoch 17/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6782 - categorical_accuracy: 0.7433 - val_loss: 0.7051 - val_categorical_accuracy: 0.7390\n",
            "Epoch 18/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6771 - categorical_accuracy: 0.7436 - val_loss: 0.7048 - val_categorical_accuracy: 0.7387\n",
            "Epoch 19/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6762 - categorical_accuracy: 0.7434 - val_loss: 0.7062 - val_categorical_accuracy: 0.7381\n",
            "Epoch 20/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6752 - categorical_accuracy: 0.7428 - val_loss: 0.7045 - val_categorical_accuracy: 0.7384\n",
            "\n",
            "Epoch 00020: val_categorical_accuracy improved from 0.73835 to 0.73838, saving model to model\n",
            "Epoch 21/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6743 - categorical_accuracy: 0.7436 - val_loss: 0.7030 - val_categorical_accuracy: 0.7390\n",
            "Epoch 22/100\n",
            "213642/213642 [==============================] - 7s 31us/step - loss: 0.6734 - categorical_accuracy: 0.7435 - val_loss: 0.7044 - val_categorical_accuracy: 0.7377\n",
            "Epoch 23/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6726 - categorical_accuracy: 0.7440 - val_loss: 0.7033 - val_categorical_accuracy: 0.7382\n",
            "Epoch 24/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6714 - categorical_accuracy: 0.7446 - val_loss: 0.7035 - val_categorical_accuracy: 0.7383\n",
            "Epoch 25/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6707 - categorical_accuracy: 0.7441 - val_loss: 0.7030 - val_categorical_accuracy: 0.7391\n",
            "\n",
            "Epoch 00025: val_categorical_accuracy improved from 0.73838 to 0.73906, saving model to model\n",
            "Epoch 26/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6698 - categorical_accuracy: 0.7441 - val_loss: 0.7038 - val_categorical_accuracy: 0.7389\n",
            "Epoch 27/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6688 - categorical_accuracy: 0.7444 - val_loss: 0.7038 - val_categorical_accuracy: 0.7385\n",
            "Epoch 28/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6681 - categorical_accuracy: 0.7445 - val_loss: 0.7028 - val_categorical_accuracy: 0.7392\n",
            "Epoch 29/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6670 - categorical_accuracy: 0.7448 - val_loss: 0.7023 - val_categorical_accuracy: 0.7386\n",
            "Epoch 30/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6664 - categorical_accuracy: 0.7449 - val_loss: 0.7027 - val_categorical_accuracy: 0.7398\n",
            "\n",
            "Epoch 00030: val_categorical_accuracy improved from 0.73906 to 0.73979, saving model to model\n",
            "Epoch 31/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6656 - categorical_accuracy: 0.7451 - val_loss: 0.7032 - val_categorical_accuracy: 0.7391\n",
            "Epoch 32/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6647 - categorical_accuracy: 0.7451 - val_loss: 0.7029 - val_categorical_accuracy: 0.7383\n",
            "Epoch 33/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6639 - categorical_accuracy: 0.7453 - val_loss: 0.7023 - val_categorical_accuracy: 0.7398\n",
            "Epoch 34/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6632 - categorical_accuracy: 0.7458 - val_loss: 0.7019 - val_categorical_accuracy: 0.7394\n",
            "Epoch 35/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6624 - categorical_accuracy: 0.7451 - val_loss: 0.7021 - val_categorical_accuracy: 0.7375\n",
            "\n",
            "Epoch 00035: val_categorical_accuracy did not improve from 0.73979\n",
            "Epoch 36/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6617 - categorical_accuracy: 0.7451 - val_loss: 0.7009 - val_categorical_accuracy: 0.7386\n",
            "Epoch 37/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6608 - categorical_accuracy: 0.7456 - val_loss: 0.7013 - val_categorical_accuracy: 0.7391\n",
            "Epoch 38/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6603 - categorical_accuracy: 0.7457 - val_loss: 0.7009 - val_categorical_accuracy: 0.7393\n",
            "Epoch 39/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6597 - categorical_accuracy: 0.7457 - val_loss: 0.7012 - val_categorical_accuracy: 0.7391\n",
            "Epoch 40/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6588 - categorical_accuracy: 0.7457 - val_loss: 0.7014 - val_categorical_accuracy: 0.7388\n",
            "\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.73979\n",
            "Epoch 41/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6581 - categorical_accuracy: 0.7459 - val_loss: 0.7024 - val_categorical_accuracy: 0.7383\n",
            "Epoch 42/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6576 - categorical_accuracy: 0.7456 - val_loss: 0.7013 - val_categorical_accuracy: 0.7381\n",
            "Epoch 43/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6565 - categorical_accuracy: 0.7464 - val_loss: 0.7020 - val_categorical_accuracy: 0.7385\n",
            "Epoch 44/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6562 - categorical_accuracy: 0.7460 - val_loss: 0.7015 - val_categorical_accuracy: 0.7388\n",
            "Epoch 45/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6555 - categorical_accuracy: 0.7459 - val_loss: 0.7018 - val_categorical_accuracy: 0.7401\n",
            "\n",
            "Epoch 00045: val_categorical_accuracy improved from 0.73979 to 0.74012, saving model to model\n",
            "Epoch 46/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6549 - categorical_accuracy: 0.7466 - val_loss: 0.7010 - val_categorical_accuracy: 0.7390\n",
            "Epoch 47/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6541 - categorical_accuracy: 0.7461 - val_loss: 0.7008 - val_categorical_accuracy: 0.7390\n",
            "Epoch 48/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6535 - categorical_accuracy: 0.7465 - val_loss: 0.7024 - val_categorical_accuracy: 0.7388\n",
            "Epoch 49/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6528 - categorical_accuracy: 0.7461 - val_loss: 0.7009 - val_categorical_accuracy: 0.7383\n",
            "Epoch 50/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6525 - categorical_accuracy: 0.7466 - val_loss: 0.7018 - val_categorical_accuracy: 0.7383\n",
            "\n",
            "Epoch 00050: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 51/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6520 - categorical_accuracy: 0.7465 - val_loss: 0.7029 - val_categorical_accuracy: 0.7383\n",
            "Epoch 52/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6514 - categorical_accuracy: 0.7467 - val_loss: 0.7014 - val_categorical_accuracy: 0.7386\n",
            "Epoch 53/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6504 - categorical_accuracy: 0.7470 - val_loss: 0.7012 - val_categorical_accuracy: 0.7381\n",
            "Epoch 54/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6498 - categorical_accuracy: 0.7470 - val_loss: 0.7010 - val_categorical_accuracy: 0.7391\n",
            "Epoch 55/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6494 - categorical_accuracy: 0.7476 - val_loss: 0.7016 - val_categorical_accuracy: 0.7391\n",
            "\n",
            "Epoch 00055: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 56/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6487 - categorical_accuracy: 0.7477 - val_loss: 0.7019 - val_categorical_accuracy: 0.7390\n",
            "Epoch 57/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6484 - categorical_accuracy: 0.7472 - val_loss: 0.7013 - val_categorical_accuracy: 0.7384\n",
            "Epoch 58/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6479 - categorical_accuracy: 0.7470 - val_loss: 0.7011 - val_categorical_accuracy: 0.7382\n",
            "Epoch 59/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6470 - categorical_accuracy: 0.7476 - val_loss: 0.7007 - val_categorical_accuracy: 0.7388\n",
            "Epoch 60/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6468 - categorical_accuracy: 0.7470 - val_loss: 0.7012 - val_categorical_accuracy: 0.7380\n",
            "\n",
            "Epoch 00060: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 61/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6461 - categorical_accuracy: 0.7477 - val_loss: 0.7016 - val_categorical_accuracy: 0.7381\n",
            "Epoch 62/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6456 - categorical_accuracy: 0.7470 - val_loss: 0.7007 - val_categorical_accuracy: 0.7379\n",
            "Epoch 63/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6451 - categorical_accuracy: 0.7471 - val_loss: 0.7033 - val_categorical_accuracy: 0.7378\n",
            "Epoch 64/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6445 - categorical_accuracy: 0.7478 - val_loss: 0.7018 - val_categorical_accuracy: 0.7387\n",
            "Epoch 65/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6442 - categorical_accuracy: 0.7479 - val_loss: 0.7023 - val_categorical_accuracy: 0.7374\n",
            "\n",
            "Epoch 00065: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 66/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6435 - categorical_accuracy: 0.7477 - val_loss: 0.7041 - val_categorical_accuracy: 0.7360\n",
            "Epoch 67/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6431 - categorical_accuracy: 0.7476 - val_loss: 0.7040 - val_categorical_accuracy: 0.7375\n",
            "Epoch 68/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6427 - categorical_accuracy: 0.7475 - val_loss: 0.7027 - val_categorical_accuracy: 0.7383\n",
            "Epoch 69/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6419 - categorical_accuracy: 0.7476 - val_loss: 0.7020 - val_categorical_accuracy: 0.7386\n",
            "Epoch 70/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6415 - categorical_accuracy: 0.7477 - val_loss: 0.7037 - val_categorical_accuracy: 0.7370\n",
            "\n",
            "Epoch 00070: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 71/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6412 - categorical_accuracy: 0.7482 - val_loss: 0.7022 - val_categorical_accuracy: 0.7386\n",
            "Epoch 72/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6405 - categorical_accuracy: 0.7480 - val_loss: 0.7023 - val_categorical_accuracy: 0.7371\n",
            "Epoch 73/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6400 - categorical_accuracy: 0.7483 - val_loss: 0.7025 - val_categorical_accuracy: 0.7371\n",
            "Epoch 74/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6397 - categorical_accuracy: 0.7477 - val_loss: 0.7020 - val_categorical_accuracy: 0.7380\n",
            "Epoch 75/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6391 - categorical_accuracy: 0.7479 - val_loss: 0.7038 - val_categorical_accuracy: 0.7367\n",
            "\n",
            "Epoch 00075: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 76/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6386 - categorical_accuracy: 0.7480 - val_loss: 0.7030 - val_categorical_accuracy: 0.7361\n",
            "Epoch 77/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6383 - categorical_accuracy: 0.7479 - val_loss: 0.7045 - val_categorical_accuracy: 0.7377\n",
            "Epoch 78/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6379 - categorical_accuracy: 0.7486 - val_loss: 0.7047 - val_categorical_accuracy: 0.7374\n",
            "Epoch 79/100\n",
            "213642/213642 [==============================] - 6s 30us/step - loss: 0.6375 - categorical_accuracy: 0.7483 - val_loss: 0.7047 - val_categorical_accuracy: 0.7364\n",
            "Epoch 80/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6368 - categorical_accuracy: 0.7480 - val_loss: 0.7041 - val_categorical_accuracy: 0.7383\n",
            "\n",
            "Epoch 00080: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 81/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6365 - categorical_accuracy: 0.7483 - val_loss: 0.7038 - val_categorical_accuracy: 0.7374\n",
            "Epoch 82/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6361 - categorical_accuracy: 0.7484 - val_loss: 0.7042 - val_categorical_accuracy: 0.7361\n",
            "Epoch 83/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6356 - categorical_accuracy: 0.7485 - val_loss: 0.7041 - val_categorical_accuracy: 0.7364\n",
            "Epoch 84/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6352 - categorical_accuracy: 0.7488 - val_loss: 0.7040 - val_categorical_accuracy: 0.7371\n",
            "Epoch 85/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6346 - categorical_accuracy: 0.7490 - val_loss: 0.7047 - val_categorical_accuracy: 0.7366\n",
            "\n",
            "Epoch 00085: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 86/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6344 - categorical_accuracy: 0.7487 - val_loss: 0.7045 - val_categorical_accuracy: 0.7357\n",
            "Epoch 87/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6342 - categorical_accuracy: 0.7488 - val_loss: 0.7055 - val_categorical_accuracy: 0.7353\n",
            "Epoch 88/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6336 - categorical_accuracy: 0.7489 - val_loss: 0.7064 - val_categorical_accuracy: 0.7372\n",
            "Epoch 89/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6332 - categorical_accuracy: 0.7488 - val_loss: 0.7056 - val_categorical_accuracy: 0.7366\n",
            "Epoch 90/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6329 - categorical_accuracy: 0.7487 - val_loss: 0.7056 - val_categorical_accuracy: 0.7354\n",
            "\n",
            "Epoch 00090: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 91/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6324 - categorical_accuracy: 0.7491 - val_loss: 0.7062 - val_categorical_accuracy: 0.7367\n",
            "Epoch 92/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6322 - categorical_accuracy: 0.7489 - val_loss: 0.7051 - val_categorical_accuracy: 0.7364\n",
            "Epoch 93/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6316 - categorical_accuracy: 0.7485 - val_loss: 0.7062 - val_categorical_accuracy: 0.7367\n",
            "Epoch 94/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6313 - categorical_accuracy: 0.7492 - val_loss: 0.7059 - val_categorical_accuracy: 0.7371\n",
            "Epoch 95/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6308 - categorical_accuracy: 0.7493 - val_loss: 0.7057 - val_categorical_accuracy: 0.7370\n",
            "\n",
            "Epoch 00095: val_categorical_accuracy did not improve from 0.74012\n",
            "Epoch 96/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6306 - categorical_accuracy: 0.7488 - val_loss: 0.7055 - val_categorical_accuracy: 0.7370\n",
            "Epoch 97/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6300 - categorical_accuracy: 0.7488 - val_loss: 0.7057 - val_categorical_accuracy: 0.7366\n",
            "Epoch 98/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6297 - categorical_accuracy: 0.7492 - val_loss: 0.7051 - val_categorical_accuracy: 0.7365\n",
            "Epoch 99/100\n",
            "213642/213642 [==============================] - 6s 28us/step - loss: 0.6293 - categorical_accuracy: 0.7490 - val_loss: 0.7069 - val_categorical_accuracy: 0.7357\n",
            "Epoch 100/100\n",
            "213642/213642 [==============================] - 6s 29us/step - loss: 0.6291 - categorical_accuracy: 0.7494 - val_loss: 0.7082 - val_categorical_accuracy: 0.7364\n",
            "\n",
            "Epoch 00100: val_categorical_accuracy did not improve from 0.74012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWDUzePqwh0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ywTF9fwsyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe734fac-c59c-4e3c-bfaa-f97f6bf9c65b"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, vocab.index('%')] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = vocab[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '^' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "start_char = np.zeros(38)\n",
        "start_char[vocab.index('%')] = 1\n",
        "start_seq = np.concatenate([start_char[np.newaxis,:], repeated_feature_matrix_train[0][np.newaxis,:]], axis=1)[np.newaxis,:,:]\n",
        "decode_sequence(start_seq)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CCCCCCCCOCOCCCCCCCCCCC@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}